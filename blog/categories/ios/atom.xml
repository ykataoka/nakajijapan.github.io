<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[categories: iOS | Nakajijapan]]></title>
  <link href="http://nakajijapan.github.io/blog/categories/ios/atom.xml" rel="self"/>
  <link href="http://nakajijapan.github.io/"/>
  <updated>2014-07-19T21:49:51+09:00</updated>
  <id>http://nakajijapan.github.io/</id>
  <author>
    <name><![CDATA[nakajijapan]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Swift勉強会を開催してきました。]]></title>
    <link href="http://nakajijapan.github.io/blog/2014/07/19/swift-shibuya-01/"/>
    <updated>2014-07-19T20:08:00+09:00</updated>
    <id>http://nakajijapan.github.io/blog/2014/07/19/swift-shibuya-01</id>
    <content type="html"><![CDATA[<script async class="speakerdeck-embed" data-id="a9200910f163013106da6eb14261a8ef" data-ratio="1.33333333333333" src="http://nakajijapan.github.io//speakerdeck.com/assets/embed.js"></script>


<p>先日、小さい規模ながらSwfit勉強会を開催しました。</p>

<p><a href="http://atnd.org/events/52641">Swift勉強会 hosted by @nakajijapan from ペパボ</a></p>

<p>そんななか、自分も「Swiftに慣れるまで行ったこと」を発表しました。</p>

<p>ざっくり言うSwiftに慣れるのに以下のことをしてみた献じたことを話しました。</p>

<ol>
<li>公式ドキュメント（を読んだ後に）</li>
<li>サンプルアプリをTableViewControllerベースで作成してみたこと</li>
<li>自分のプラグイン(NKJMovieComposer)をSwiftで書き換えてみたこと</li>
<li>気分高ぶってMac OS Xも作成してみたこと</li>
</ol>


<p>詳しくはスライドをご覧ください。</p>

<p>Swiftが出たときにSan Franciscoで一心不乱にサンプルアプリプログラム書いてブログ上げようかと思ったけど
いろんな人が既にブログに上げていたのでただただGitHubにあげるだけでした。そんなんか
いろいろ勉強していくうちにMacアプリもつくれんじゃねーかwで脳内麻痺して書籍を購入してSwiftで作成
してみました。</p>

<p><img src="/images/posts/2014-07-19-01.png" alt="swift" /></p>

<p>起動しとけば単純に画像を定期的に保存するアプリです。
（そのうちに１日で保存した画像をGifアニメのような動画にしてソーシャルにアップする機能作ろうかと計画中）
ある程度できたらGeHubにアップ仕様と思います。</p>

<p>ちなみにこちらの書籍を購入しました。</p>

<p><a href="http://frustration.me/items/5171">
  <img src="http://ecx.images-amazon.com/images/I/41bAmGQ-ljL.jpg" />
</a></p>

<p>Macアプリ、知識が溜まって来たらまた記事にします。</p>

<p>とにかく、Swift勉強会が無事終えてよかったです。
参加してくれたみなさん、そして発表してくれた、@misyobun @hypermkt @kurotaky ありがとうございました！！！</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Xcodeのフォルダ参照]]></title>
    <link href="http://nakajijapan.github.io/blog/2014/07/11/xcode-folder-references/"/>
    <updated>2014-07-11T00:37:00+09:00</updated>
    <id>http://nakajijapan.github.io/blog/2014/07/11/xcode-folder-references</id>
    <content type="html"><![CDATA[<p>なにげに今まで知らなかったんですが結構便利だってことに最近気づいたのでメモ。
普段リソースをXcodeに関連づけさせるためにドラッグアンドドロップさせていたのですが、
一旦以下のチェック項目でディレクトリ参照にしてしまえば、これ以降リソースファイルを追加したときに毎度
ドラッグアンドドロップさせなくてよく、自動的に追加されます。</p>

<p><img src="/images/posts/2014-07-11-01.png" alt="nakajijapan" /></p>

<p><img src="/images/posts/2014-07-11-02.png" alt="nakajijapan" /></p>

<p>他と違うのは対象のディレクトリは色が青になっています。</p>

<p>実際に呼び出すときには通常の呼び出し方法と異なります。リソースファイルの前に指定のディレクトリ名を宣言
する必要があります。</p>

<p>今回だと以下の感じになります。</p>

<p><code>
let soundFilePath = NSBundle.mainBundle().pathForResource("music/sound001", ofType: "mp3")
</code></p>

<p><code>music</code>がディレクトリにあたりますね。</p>

<p>これ、何気に便利で、デザイナさんにXcode立ち上げなくても指定のディレクトリおいておくだけで、余計なところを実装せずに済むので
仕事が捗るのではないかと気づいた今日このごろでした。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[録画時にブラックシーンができてしまう問題]]></title>
    <link href="http://nakajijapan.github.io/blog/2014/06/15/study-avassetwriter/"/>
    <updated>2014-06-15T18:26:00+09:00</updated>
    <id>http://nakajijapan.github.io/blog/2014/06/15/study-avassetwriter</id>
    <content type="html"><![CDATA[<p><a href="http://nakajijapan.github.io/blog/2014/06/08/wwdc2014/">WWDC2014に行って来た</a>の話になるのですが、
プライベートでアプリ作成しているときにAV Foundation絡みでわからないところがあったのでAppleのエンジニアさんに質問してきました。</p>

<h2>現象</h2>

<p>問題は、自分が作成した<a href="https://github.com/nakajijapan/NKJMultiMovieCaptureView">NKJMultiMovieCaptureView</a>でその現象が発生しました。
作成したときの話は<a href="http://nakajijapan.github.io/blog/2014/06/01/app-doujou3/">こちら</a>になります。
Vine動画のようにタッチしたら録画し、タッチが終了したら(指を離したら)録画を終了し、録画した複数の動画を一つにする仕組みを作成したのですが、
実際作成した動画を見てみると最初のほんの一瞬だけなぜかブラックシーンができてしまいます。</p>

<p>現状の処理として以下のようなことをしています。</p>

<h3>1. 録画開始</h3>

<p><code>obj-c
- (void)touchesBegan:(NSSet *)touches withEvent:(UIEvent *)event
</code></p>

<p>タッチイベントで録画の処理を開始します。このときにファイルに対しての書き込み処理を開始します。</p>

<p><code>obj-c
[self.assetWriter startWriting];
[self.assetWriter startSessionAtSourceTime:self.recordStartTime];
</code></p>

<h3>2. 録画</h3>

<p><code>AVCaptureVideoDataOutputSampleBufferDelegate</code>, <code>AVCaptureAudioDataOutputSampleBufferDelegate</code>をプロトコルとして指定して、
以下のメソッドで録画の処理を行います。</p>

<p><code>obj-c
- (void)captureOutput:(AVCaptureOutput *)captureOutput didOutputSampleBuffer:(CMSampleBufferRef)sampleBuffer fromConnection:(AVCaptureConnection *)connection
</code></p>

<p>ざっくりですが、内部でやっていることはCMSampleBufferというフレーム情報が取得でき、それを１秒間に何回も実行されるこのメソッドで<code>AVAssetWriterInput</code>オブジェクトに
追加処理をしています。</p>

<p>```obj-c</p>

<pre><code>CFRetain(sampleBuffer);
CFRetain(formatDescription);
dispatch_async(self.movieWritingQueue, ^{

    if (_assetWriter.status == AVAssetWriterStatusWriting) {

        if (assetWriterInput.readyForMoreMediaData) {

            if (![assetWriterInput appendSampleBuffer:sampleBuffer]) {
                NSLog(@"%@",[self.assetWriter error]);
            }

        }
    }

    CFRelease(sampleBuffer);
    CFRelease(formatDescription);
});
</code></pre>

<p>```</p>

<h3>3. 録画終了</h3>

<p>タッチが終了したら録画終了の処理を行います。</p>

<p><code>obj-c
- (void)touchesEnded:(NSSet *)touches withEvent:(UIEvent *)event
</code></p>

<h2>問題</h2>

<p>どうやらスレッドを利用しての保存方法に問題があったようです。</p>

<h3>修正前</h3>

<p><img src="/images/posts/2014-06-15_01_avassetwriter.jpg" alt="AVAssetWriter" /></p>

<p>録画開始とフレーム情報を保存する処理が別スレッドで行われているせいで微妙にタイミングがずれたフレーム情報を取得してしまっている。
ここっだと、開始した時間よりも一瞬だけ先のフレーム情報を取得してしまうので最初の一瞬はブラックシーンになります。</p>

<h3>修正後</h3>

<p><img src="/images/posts/2014-06-15_02_avassetwriter.jpg" alt="AVAssetWriter" /></p>

<p>なので録画開始も同じスレッドで順次処理させるようにし、時間の誤差を最小限にしました。こうすることで無事ブラックシーンが無くなりました。</p>

<p>実際には以下のように修正しています。</p>

<p>```diff</p>

<pre><code> // Record
 NSLog(@"[Starting to record]");
</code></pre>

<ul>
<li> [self.assetWriter startWriting];</li>
<li> [self.assetWriter startSessionAtSourceTime:self.recordStartTime];</li>
<li> dispatch_async(self.movieWritingQueue, ^{</li>
<li><pre><code> [self.assetWriter startWriting];
</code></pre></li>
<li><pre><code> [self.assetWriter startSessionAtSourceTime:self.recordStartTime];
</code></pre></li>
<li> });
+
```</li>
</ul>


<h3>まとめ</h3>

<p>とはいえ、この実装も完璧というわけではなくてタイミングがずれることはあるとおっしゃっていましたが、
今のところ発生していないので安心しています。</p>

<h2>参考</h2>

<ul>
<li><a href="https://developer.apple.com/library/ios/documentation/AVFoundation/Reference/AVAssetWriter_Class/Reference/Reference.html">AVAssetWriter Class Reference</a></li>
<li><a href="https://developer.apple.com/library/ios/documentation/Cocoa/Conceptual/Multithreading/Multithreading.pdf">Threading Programming Guide</a></li>
<li><a href="https://developer.apple.com/library/ios/documentation/General/Conceptual/ConcurrencyProgrammingGuide/Introduction/Introduction.html#//apple_ref/doc/uid/TP40008091">Concurrency Programming Guide</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[WWDC2014に参加してきました]]></title>
    <link href="http://nakajijapan.github.io/blog/2014/06/08/wwdc2014/"/>
    <updated>2014-06-08T23:50:00+09:00</updated>
    <id>http://nakajijapan.github.io/blog/2014/06/08/wwdc2014</id>
    <content type="html"><![CDATA[<p><a href="https://developer.apple.com/wwdc/">
  <img src="https://devimages.apple.com.edgekey.net/wwdc/images/wwdc14-home-branding.png" width=800/>
</a></p>

<p>今回、アプリエンジニアなら一度は行ってみたいはずのWWDC2014に行くことになりました。そこで、この一週間いろんなこと起きたので何回かに分けてブログという形で記録に残しておきたいと思います。</p>

<h2>経緯</h2>

<p>ここ最近の２、３年はプライベートでアプリを作る時間の割合がどんどん大きくなってきて何個かアプリを出したり、CocoaPodsでプラグインを出したりと活動して来たわけですが、その成果もあってかないのか仕事でもアプリの仕事を振られるようになって徐々に仕事もプライベートもアプリの仕事の比重が高くなってくる今日このごろでした。</p>

<p>そんななか同僚の<a href="https://twitter.com/misyobun">@misyobun</a> <a href="https://twitter.com/daniel0613">@daniel0613</a>と今年のWWDCはどうしようかという話になって、たしかにいち早くセッションの内容が見れたりLabで開発者の人に質問したりと魅力たっぷりなのですが予算とか有給とか上長の許可とか。。。。超えなければいけない壁あったのですが、まぁ当選に受かったらその後のことは後で考えようということで駄目もとで応募してみました。</p>

<p>その後、突如何の前触れもなく当選したというメールがきたのでびっくりしました。じわじわきた感じです。とはいえ、これからどうしたものかと思いとにかく基盤の方、事業部長、上長、人事の方に相談していろいろありましたが、WWDCに行く承認がおりましてめでたく参加という形になりました。一つ奇跡がありまして僕の同僚である<a href="https://twitter.com/misyobun">@misyobun</a>も受かっていたことです。初めてのサンフランシスコで初めてのWWDCだったの一緒にいくメンバーがいたのは大変心強いものを感じました。</p>

<h2>KeyNote</h2>

<p>詳しい纏めは<a href="http://www.gizmodo.jp/2014/06/wwdc_2014_3.html">ギズモードさんの記事</a>を読んでもらった方がわかりやすいです。</p>

<p>衝撃的だったのが新しいプログラミング「Swift」が発表されたこと。
しかも、しれっとはじまったので驚きました。。。クレイグさんが「Xcode..」って言ったときにみんな”ざわっ”ってしてたのは忘れないです。
今年はiPhone6やフィットネス関係のハードが出るのかなと思いきや、iOS8、Swiftとデベロッパの祭典ならではの内容だったのかなと思います。</p>

<p><img src="https://devimages.apple.com.edgekey.net/swift/images/swift-hero.png" alt="Swift" /></p>

<h4>Swift &ndash; Objective-C without C</h4>

<p><a href="https://developer.apple.com/swift/">Introducing Swift</a></p>

<ul>
<li>安全なプログラミングパターンの提供</li>
<li>現代の機能・技術の即したものをよりシンプルに柔軟に楽しく実装できる</li>
<li>Python, Objective-Cより高速</li>
</ul>


<h3>CocoaPods MeetUp in Twillio</h3>

<p>その日は、いろんな会社でWWDCにちなんだミートアップをやっていたので自分はTwillio社で開催されていたCocoaPodsのミートアップに参加してきました。英語が早くてほとんど聞き取れなかった・・・。とはいえ、なんかコミニュケーションしようと思って発表した人に挨拶しにいきました。</p>

<iframe src="http://nakajijapan.github.io//instagram.com/p/ow-OKBsR0Y/embed/" width="612" height="710" frameborder="0" scrolling="no" allowtransparency="true"></iframe>


<h2>2日目</h2>

<p>せっかくなので自分の興味のある分野をみてきたのでした。</p>

<ul>
<li>Mastering Modern Media Playback</li>
<li>Harnessing Metadata in Audiovisual Media</li>
<li>Introducing HomeKit</li>
</ul>


<p>夜は二人でSwiftごにょごにょ</p>

<h2>3日目</h2>

<p>この日もせっかくなので自分の興味のある分野をみてきたのでした。</p>

<ul>
<li>What&rsquo;s New in Core Audio</li>
<li>Introducing HealthKit</li>
<li>Mastering Modern Media Playback</li>
<li>Harnessing Metadata in Audiovisual Media</li>
<li>Camera Capture: Manual Controls</li>
<li>Intermediate Swift</li>
<li>Swift Interoperability In Depth</li>
</ul>


<p>夜は二人でSwiftごにょごにょ</p>

<h2>4日目</h2>

<p>この日は、二人でSwiftのドキュメント読んだりプログラミングしているうちにわからないところがでてきたので一旦セッションにでることは中止して各分野のLabにいって担当のエンジニアに質問をしに行く業を行いました。</p>

<ul>
<li>Swift Lab

<ul>
<li>Swiftの実装の仕方もろもろ</li>
</ul>
</li>
<li>Media Lab

<ul>
<li>AV Foundation関連でAVAssetWriterの処理方法</li>
</ul>
</li>
</ul>


<p>その後は、Bashというなの打ち上げが庭で開催されました。</p>

<h3>5日目</h3>

<ul>
<li>Advanced Swift Debugging in LLDB</li>
</ul>


<p>時間があったのでSwift Labで質問。</p>

<h2>Bash!!!!!!!</h2>

<p>WWDCは五日間あったのですが、四日目にはBash!というなの打ち上げがあり、せっかくなので参加してきました。開会式・閉会式とかはないんですがね&hellip;これは文化の違いなのかな。あ、書いてて思ったのですが、
参加したエンジニアと交流する名目のあれだったんだな思いました。。。。Bashのプログラムが全くなかったので同僚と話していたらおばちゃんが英語で交流しなさい！！
っていわれたので何人かのエンジニアさんと会話してきましたのも思い出しました。アジアからきたりヨーロッパからきたりいろんな国のエンジニアさんと話させていただきました。
みんな英語流暢でなかなか理解できなかったのですがそこはお酒の力をかりてテンションで会話できたのでした。。。</p>

<p>途中からはライブが始まり、KeyNoteで流れていた曲のアーティスト、Bastilleがライブしたらしいです。KeyNoteを見直したら確かにこの曲でじわじわと会場にいたときの興奮がよみがえって来たので購入してしまいましたw</p>

<p><img src="http://ecx.images-amazon.com/images/I/51IANZeQuXL.jpg" alt="Bastille - Pompeii" /></p>

<p>Bad Blood &ndash; Pompeii</p>

<p>あと、本当に偶然にクレイグさんが近くにいたので一緒に写真を撮らせていただいたのは貴重な思い出です。安定のスマイルでした。</p>

<blockquote class="twitter-tweet" lang="ja"><p>Awesome!! はじめまして！ <a href="https://twitter.com/craig_apple">@craig_apple</a> <a href="https://twitter.com/search?q=%23WWDC&amp;src=hash">#WWDC</a> <a href="http://t.co/zjZ3LrzLFA">pic.twitter.com/zjZ3LrzLFA</a></p>&mdash; nakajijapan (@nakajijapan) <a href="https://twitter.com/nakajijapan/statuses/474827650419007488">2014, 6月 6</a></blockquote>


<script async src="http://nakajijapan.github.io//platform.twitter.com/widgets.js" charset="utf-8"></script>


<h2>WWDCに参加してみて</h2>

<h3>Labにもっと行こう！！！</h3>

<p>今回は初めてもありあまり用意という用意はしてこなかったのですが、実際に参加してみてセッションに躍起になって参加はしなくてもいいのかなと思いました。
今年はセッションの発表が終了してから１、２日後にはセッションの動画アップロードされているので、あまりWWDCに参加したメリットは感じられないと思います。
なのでセッションは適度にして、新しい機能や仕事やプライベートで解決できない問題纏めて各分野のLabで質問しまくるのがいいなと思いました。
実際に、Appleのエンジニアさんも、皆さんがLabで質問してくるこが大変ありがたいし大歓迎だよ！改善にもつながるしね！とおっしゃっていました。
英語もコードとサンプルプログラムで一緒に話せばなんとかなると実感しました。
もっと、質問すれば良かったと大変反省しております。</p>

<h3>沸き上がる興奮を日本に持ち帰る</h3>

<p>自慢話します。（違います）
今回参加したことを何らかの形でフィードバックして来年こそ自分が行きたい！来年も参加の許可が下りるようにする使命みたいなものは勝手にあると思っています。
もっと盛り上げたいな。まぁ自分や近くにいる人たちが楽しんでれば、勝手に集まってくるのかな。よし、もっと楽しもう！！！！</p>

<h3>戦争だ！</h3>

<p>いや、ビジネスと言う名の戦争です。
外国の方（特に英語圏）は言語の壁がないのでがんがんLabに質問していって解決したり、勝手に他のエンジニアとなかよくなって情報交換したりと圧倒されたり、
このようなエンジニアが会場でこんな多いと感じたのに正解にはもっとたくさんいるんだなと思うと自分なんてほんの点なんだなと萎縮しています。</p>

<p>そんな人と、ビジネスで闘っているとなるとなおさら。</p>

<h2>最後に</h2>

<p>相談に乗っていただいた<a href="https://twitter.com/kentaro">@kentaro</a>さん、<a href="https://twitter.com/mau_rin">@mau_rin</a>さん、
仕事がまだがんがん残っているのにも関わらず許可していただいた上長、事業部長、そしてWWDCそしてサンフランシスコで一週間心の支えになった同僚の
<a href="https://twitter.com/misyobun">@misyobun</a>には大変大変大変大変大変感謝しております。</p>

<p>この恩義は業務や後輩の育成で返していこう思います！！！！</p>

<p>ぼそっ(来年も参加したい。。。)
ぼそっ(仕事が溜まってる!!!!!)</p>

<p>以上、Apple信者のたわいもないブログでした。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[app道場#3 「よくある動画アプリのあれを実装したい」を発表した]]></title>
    <link href="http://nakajijapan.github.io/blog/2014/06/01/app-doujou3/"/>
    <updated>2014-06-01T20:05:00+09:00</updated>
    <id>http://nakajijapan.github.io/blog/2014/06/01/app-doujou3</id>
    <content type="html"><![CDATA[<p>２回目の参加となるiPhone and Android勉強会の<a href="http://atnd.org/events/50499">「app道場#3」</a>に参加してきました。</p>

<p>今回は、自分が酔った勢いで以下のような発言をしてしまい、大変誤解を招くような発言をしてしまいました。この場を借りて陳謝したいと思います。
そんなこんながありまして、弊社で勉強会を開催する運びとなりました。</p>

<blockquote class="twitter-tweet" lang="ja"><p>mixiさんに喧嘩売ってきた。</p>&mdash; nakajijapan (@nakajijapan) <a href="https://twitter.com/nakajijapan/statuses/458961908943446016">2014, 4月 23</a></blockquote>


<script async src="http://nakajijapan.github.io//platform.twitter.com/widgets.js" charset="utf-8"></script>


<p>詳細は<a href="http://www.vagrantup.jp/entry/2014/05/31/234116">「喧嘩を売る」</a>を参照すると良いでしょう。</p>

<blockquote><p>お分かりの通り、ここでいう「喧嘩を売る」は「次の勉強会を企画・開催する」と解釈されます。
「app道場」という字面的に少し物騒ではありますが「喧嘩」というフレーズは意外にも正鵠を射ているのではないかと思う次第です。（さすが、@nakajijapan）</p></blockquote>

<p>いいこといっています。</p>

<h2>本題</h2>

<p>さて、今回は「よくある動画アプリのあれを実装したい」というタイトルで、またもやAV Foundationの話になります。自分も動画周りの勉強してる身として、VineとかInstagramとかの動画のインターフェースの実装ってどうやるんだろうなと疑問に思っていました。
気になって気になってしょうがなかったのでちょっと実装してみようかなという想い、自分なりに考えて実装してみました。</p>

<script async class="speakerdeck-embed" data-id="52a36f80c901013130852e590c444dc4" data-ratio="1.33333333333333" src="http://nakajijapan.github.io//speakerdeck.com/assets/embed.js"></script>


<p>仕様自体は以下のようになっています。</p>

<ul>
<li>タッチが開始したら動画の保存を開始する</li>
<li>タッチが終了したら動画の保存を終了する</li>
<li>動画はファイルに保存する</li>
<li>それぞれ保存した動画を結合して一つの動画ファイルに結合する。</li>
</ul>


<p>詳細はスライドを見ていただくことにして、実際にいい感じにできたのでCocoaPodsに登録しました。</p>

<p><a href="https//github.com/nakajijapan/NKJMultiMovieCaptureView.git">NKJMultiMovieCaptureView</a></p>

<p>これが今回公開したpodで、SessionCaptureView部分にタッチして動画を保存するところまでの処理を提供しています。
実際の保存処理は前回作成したpod, <a href="https//github.com/nakajijapan/NKJMovieComposer.git">NKJMovieComposer</a>を利用することで簡単に実装することができます。</p>

<p>しかし、まだまだまだまだ汎用性に欠ける部分が多々あるので粛々と時間を見つけて改善していこうと思います。</p>

<h4>課題</h4>

<ul>
<li>現在は正方形のビデオサイズを主にテスト対象にしているのでいろんなサイズに対応できるようにする</li>
<li>動画を結合したときに最初の0.1?0.2?だけ真っ黒になる部分がでてしまう。</li>
</ul>


<h2>懇親会</h2>

<p>今回の勉強会にSlideStoryさんの中の人が来てくださって、動画周りのことでやんややんやお話を聞くとができたので大変勉強なりやした。
実装してみてやはり同じ課題にぶつかっていたそうです。あと何個か動画関連のpodを紹介してもらえたので時間を見つけて実装して見ようと思います。</p>

<ul>
<li><a href="https://github.com/rFlex/SCRecorder">SCRecorder</a></li>
<li><a href="https://github.com/BradLarson/GPUImage">GPUImage</a></li>
</ul>


<p>また、今回の勉強会の裏側で違う勉強会が開催されていた模様で自分と同じような内容の発表があり、大変シンクロを感じましたので紹介させていただきます。かなり驚きました！！！！w</p>

<iframe src="http://www.slideshare.net/slideshow/embed_code/35199041" width="427" height="356" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px 1px 0; margin-bottom:5px; max-width: 100%;" allowfullscreen> </iframe>


<p> <div style="margin-bottom:5px"> <strong> <a href="https://www.slideshare.net/himaratsu/6-vine" title="6秒動画アプリ Vineの作り方" target="_blank">6秒動画アプリ Vineの作り方</a> </strong> from <strong><a href="http://www.slideshare.net/himaratsu" target="_blank">Hiramatsu Ryosuke</a></strong> </div></p>

<p>最後に、勉強会準備で手伝ってくださったみなさん、app道場関係者のみなさん、本当にお疲れ様でした。また次も参加します！！</p>

<p>だれかに喧嘩売らねば！！！！！（売りません買わないでださい）</p>

<h2>Ref</h2>

<ul>
<li><a href="https://developer.apple.com/library/ios/documentation/AVFoundation/Reference/AVCaptureVideoDataOutput_Class/Reference/Reference.html">AVCaptureVideoDataOutput</a></li>
<li><a href="https://developer.apple.com/library/ios/documentation/AVFoundation/Reference/AVCaptureVideoDataOutputSampleBufferDelegate_Protocol/Reference/Reference.html#//apple_ref/occ/intfm/AVCaptureVideoDataOutputSampleBufferDelegate/captureOutput:didOutputSampleBuffer:fromConnection:">AVCaptureVideoDataOutputSampleBufferDelegate</a></li>
<li><a href="https://developer.apple.com/library/mac/documentation/AVFoundation/Reference/AVCaptureAudioDataOutputSampleBufferDelegate_Protocol/Reference/Reference.html">AVCaptureAudioDataOutputSampleBufferDelegate</a></li>
<li><a href="https://developer.apple.com/library/ios/documentation/AVFoundation/Reference/AVAssetWriter_Class/Reference/Reference.html">AVAssetWriter</a></li>
<li><a href="https://developer.apple.com/library/mac/documentation/AVFoundation/Reference/AVAssetWriterInput_Class/Reference/Reference.html">AVAssetWriterInput</a></li>
<li><a href="https://developer.apple.com/library/mac/documentation/CoreMedia/Reference/CMSampleBuffer/Reference/reference.html">CMSampleBuffer</a></li>
</ul>

]]></content>
  </entry>
  
</feed>
