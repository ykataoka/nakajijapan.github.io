<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[categories: objective-c | Nakajijapan]]></title>
  <link href="http://nakajijapan.github.io/blog/categories/objective-c/atom.xml" rel="self"/>
  <link href="http://nakajijapan.github.io/"/>
  <updated>2013-12-16T16:19:26+09:00</updated>
  <id>http://nakajijapan.github.io/</id>
  <author>
    <name><![CDATA[nakajijapan]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[AV Foundation Frameworkを利用して動画の結合を行う]]></title>
    <link href="http://nakajijapan.github.io/blog/2013/10/22/how-to-combine-some-movies-with-avfoundation/"/>
    <updated>2013-10-22T23:08:00+09:00</updated>
    <id>http://nakajijapan.github.io/blog/2013/10/22/how-to-combine-some-movies-with-avfoundation</id>
    <content type="html"><![CDATA[<p>こんにちはあのnakajijapanです。
以前、<a href="http://owkr.info/movie/">心霊動画アプリで「もう一度ご覧いただこう」</a> というアプリをリリースしました。
心霊動画アプリなので動画と動画を結合したり動画の上に動画を重ねて実装したりといろいろ
やるわけですが今回はじめてということもあり沢山勉強になったのでここいらで自分の頭の整理
がてら情報をまためようと思います。</p>

<p>今回主に利用したのが「AV Foundation」です。</p>

<p>ざっくりいうとメディア情報（動画）を細かく制御できるようにしたフレームワークで、メタ情報の
取得、作成、編集、再エンコードができたりできます。</p>

<p>階層的には以下のような階層に存在して、簡単に動画とか写真の処理をしたい場合は</p>

<ul>
<li>Media Player Framework(MPMoviePlayerController, MPMoviePlayerViewController)</li>
<li>UIKit(UIIMagePickerController)</li>
</ul>


<p>を実装すれば難なく実装できちゃいます。ただ、今回は動画にいろんなエフェクトをいれたいのでもっと細かく制御
できる下の階層のフレームワークを使いました。感覚的に細かい制御できるようになるのでそのぶん面倒くさいのは
いうまでもありません。</p>

<p><img src="/images/posts/2013-10-22_01.png" alt="AV Foundation" />
<a href="https://developer.apple.com/library/ios/documentation/AudioVideo/Conceptual/AVFoundationPG/Articles/00_Introduction.html">https://developer.apple.com/library/ios/documentation/AudioVideo/Conceptual/AVFoundationPG/Articles/00_Introduction.html</a></p>

<p>では実際にどう実装していけばいいかなのですが、そのために結構なクラスを利用するのでそれぞれざっくり説明していきます。</p>

<h3>AVAsset</h3>

<p>iPodや写真ライブラリのメディア情報をオブジェクトとして保持することができ、これからいろんなの情報を切り出して取得すること
ができます。</p>

<p><code>obj-c
AVAsset*                   videoAsset;
videoAsset = [[AVURLAsset alloc] initWithURL:movieUrl options:nil];
</code></p>

<h3>AVAssetTrack</h3>

<p>アセットの情報からトラックレベルで切り出した情報。（うまく翻訳できなかった・・・）
例えば、アセットから動画と音声に切り分ける。</p>

<p>```obj-c
AVAsset<em>                   videoAsset;
AVAssetTrack</em>              videoTrack;
AVAssetTrack*              audioTrack;</p>

<p>videoAsset = [[AVURLAsset alloc] initWithURL:movieUrl options:nil];</p>

<p>// アセットからトラックを取得
videoTrack = [[videoAsset tracksWithMediaType:AVMediaTypeVideo] objectAtIndex:0];
audioTrack = [[videoAsset tracksWithMediaType:AVMediaTypeAudio] objectAtIndex:0];
```</p>

<h3>AVMutableComposition</h3>

<p>様々なメディア情報を結合したものです。このクラスで様々に編集された動画や音声を結合したり、時間の制御をしたり
するクラスです。最終的にAVAssetExportSessionに渡してエキスポート処理（実際にファイルに保存する）します。</p>

<p>```obj-c
AVMutableComposition<em>      mixComposition;
AVMutableCompositionTrack</em> compositionVideoTrack;</p>

<p>// コンポジション作成
mixComposition = [AVMutableComposition composition];
compositionVideoTrack = [mixComposition addMutableTrackWithMediaType:AVMediaTypeVideo preferredTrackID:kCMPersistentTrackID_Invalid];
```</p>

<h3>AVMutableVideoComposition</h3>

<p>AVMutableCompositionで新しいトラックを追加したときに返り値としてとれるもです。追加されたオブジェクトの参照で空のトラックって感じなんでしょうか。
ここに実際のメディア情報を入れていきます。メディアタイプで動画とか音声とか格納することができます。あと、この動画の何秒
から何秒間を何秒目に結合させるとかできたりします。</p>

<p>```obj-c
compositionVideoTrack = [mixComposition addMutableTrackWithMediaType:AVMediaTypeVideo preferredTrackID:kCMPersistentTrackID_Invalid];</p>

<p>[compositionVideoTrack insertTimeRange:CMTimeRangeMake(kCMTimeZero, timeDuration)</p>

<pre><code>                           ofTrack:_videoTrack
                            atTime:kCMTimeZero
                             error:nil];
</code></pre>

<p>[compositionVideoTrack setPreferredTransform:[videoTrack preferredTransform]];
```</p>

<h3>AVMutableVideoCompositionLayerInstruction</h3>

<p>アセットのトラックに対して回転、透過度、クロッピングができます。</p>

<p>```obj-c
// ここでは動画を小さくして指定の位置へ移動させてます。
CGAffineTransform scale      = CGAffineTransformMakeScale(0.30f, 0.30f);
CGAffineTransform trnsration = CGAffineTransformMakeTranslation(30, 406);</p>

<p>AVMutableVideoCompositionLayerInstruction* <em>layerInstruction;
</em>layerInstruction = [AVMutableVideoCompositionLayerInstruction videoCompositionLayerInstructionWithAssetTrack:<em>compositionVideoTrack];
[</em>layerInstruction setTransform:CGAffineTransformConcat(scale, trnsration) atTime:kCMTimeZero];
```</p>

<h2>AVAssetExportSession</h2>

<p>さまざまなアセット情報を利用して指定されたフォーマットに変換したり動画のトリミングを行います。
例えば、mov形式、720x720サイズでファイルに保存させたりできます。</p>

<p>```obj-c
videoComp = [AVMutableVideoComposition videoComposition];
videoComp.renderSize    = CGSizeMake(720, 720);
videoComp.frameDuration = CMTimeMake(1, 24); // framerate</p>

<p>// AVCompositionをベースにAVAssetExportを生成
assetExportSession = [[AVAssetExportSession alloc] initWithAsset:mixComposition presetName:AVAssetExportPreset1280x720];</p>

<p>// 合成用のVideoCompositionを設定
assetExportSession.videoComposition = videoComp;</p>

<p>// エクスポートファイルの設定
NSURL *composedMovieUrl = [NSURL fileURLWithPath:composedMoviePath];
assetExportSession.outputFileType = AVFileTypeQuickTimeMovie;
assetExportSession.outputURL = composedMovieUrl;
assetExportSession.shouldOptimizeForNetworkUse = YES;</p>

<p>// エキスポート処理
[assetExportSession exportAsynchronouslyWithCompletionHandler:^{</p>

<pre><code>switch ([exportSession status]) {
    case AVAssetExportSessionStatusFailed:
        NSLog(@"Export failed: %@", [[exportSession error] localizedDescription]);
        break;
    case AVAssetExportSessionStatusCancelled:
        NSLog(@"Export canceled");
        break;
    default:
        break;
}
</code></pre>

<p>}];
```</p>

<p>主に利用するクラスを説明しました。これらを駆使して実装すれば簡単な動画の結合ができるようになります。</p>

<p>だいたいの大枠は以下の図を見ると何となくわかるかもしれませんね。</p>

<p><img src="/images/posts/2013-10-22_02.png" alt="Editing" />
<a href="https://developer.apple.com/library/ios/DOCUMENTATION/AudioVideo/Conceptual/AVFoundationPG/Articles/03_Editing.html">https://developer.apple.com/library/ios/DOCUMENTATION/AudioVideo/Conceptual/AVFoundationPG/Articles/03_Editing.html</a></p>

<h2>まとめ</h2>

<p>どうでしょう。ざっくりとですが動画を結合するのに必要なクラスの説明とどのように実装されていくのかをざっくり
説明しました。本当に最初の方は？？？となってしまうと思いますが実装していくうちに分かってくるようになります。
あとこれ系の情報はあんまりネット上にはないのでしっかりと学びたいもっと動画カスタマイズしたという人がいれば
やはり<code>AV Foundation Programming Guide</code>をじっくり読むのが最短だししっかり理解できるとおもいました。あと困った
ことがあったら <a href="http://stackoverflow.com/">http://stackoverflow.com/</a> で同じ人が困っているかもしれないのでみるといいです。</p>

<p>応用編としては動画をスローモーションにさせたり、ワイプのような動画を作成したり、画像をアニメーションさせたりと
いろいろありますが説明していこうと思います。というか時間がたったら忘れそうな知識なのでやります。。。</p>

<h2>Reference</h2>

<ul>
<li><a href="https://developer.apple.com/library/ios/documentation/AudioVideo/Conceptual/AVFoundationPG/AVFoundationPG.pdf">AV Foundation Programming Guide</a></li>
<li><a href="https://developer.apple.com/wwdc/videos/">Moving to AV Kit and AV Foundation &ndash; 606</a></li>
<li><a href="https://developer.apple.com/wwdc/videos/">Core Image Effects and Techniques &ndash; 509</a></li>
<li><a href="https://developer.apple.com/wwdc/videos/">Advanced Editing with AV Foundation &ndash; 612</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[心霊動画アプリ 「もう一度ご覧いただこう」をリリースしました。]]></title>
    <link href="http://nakajijapan.github.io/blog/2013/09/30/released-iphone-app-ghost-movie/"/>
    <updated>2013-09-30T02:17:00+09:00</updated>
    <id>http://nakajijapan.github.io/blog/2013/09/30/released-iphone-app-ghost-movie</id>
    <content type="html"><![CDATA[<p><img src="http://a1745.phobos.apple.com/us/r30/Purple6/v4/88/a2/77/88a27754-3407-af16-2c8d-2bfec9c508f0/mzl.llawgtne.png" alt="心霊動画アプリ もう一度ご覧いただこう" /></p>

<p><a href="https://itunes.apple.com/jp/app/the-ghost-movie-app-look-again/id696530211?mt=8" target="_blank"><img src="http://nakajijapan.github.io/images/apple_store.png" /></a></p>

<p>先日ではありますがnakajijapan所属するチーム「恥知らず」で次なるアプリをリリースしました。
その名も</p>

<h3>心霊動画アプリ 「もう一度ご覧いただこう」</h3>

<p><a href="http://owkr.info/movie">http://owkr.info/movie</a></p>

<p>です。</p>

<p>構想は３年前からあったのですが僕の技術力不足で無理！とか言って、最初はその前進となる</p>

<h3>心霊写真アプリ「おわかりいただけただろうか」</h3>

<p><a href="http://owkr.info">http://owkr.info</a></p>

<p>を作成しました。その後時を経て、そろそろできるんじゃねという根拠ない自信がありまして
作成するにいたった次第です。今回はそのリリースが出来ましたよっていうご報告であります！</p>

<p>今回動画アプリを作成してみて、自分としてグッドっだったのは</p>

<ul>
<li>AVFoundationガリガリガリガリいじったし（未知の領域への挑戦）

<ul>
<li>動画動詞の結合</li>
<li>動画内でのアニメーション</li>
<li>動画のスローモーション</li>
<li>動画内に動画をいれる（ワイプ）</li>
</ul>
</li>
<li>いろんなTips学んだ

<ul>
<li>シュミレータで効率的に開発していく方法</li>
<li>iOSのバージョンのデザインの差異（主に位置によるずれ）の直し方</li>
</ul>
</li>
<li>キャンペーンの出し方

<ul>
<li>以前にリリースアプリと連携デザインに統一感をもたせた</li>
</ul>
</li>
</ul>


<p>失敗や改善した方がいいなというのも何個かあって</p>

<p>iOS7でチェックしとけばよかった。しかもガンガンみんなiOS7にしてしまったのでこれはつらかった・・
iOS7でテストして仮に問題が発生したときにその対応でリリースが遅れるのは避けたかったのでちょっと
最後まで避けてたのが仇となりました。無念。やりかたとしては、新しいバージョンがリリース間近に
なった場合はかならず確認を行うことをマストにしたほうがいいですね。これ勉強！</p>

<p>リリースタイミングを逃しました。本当は夏にリリースすれば良かったのですが僕の技術力不足であえなく断念して
しまいました。。。</p>

<p>あとは、デザイナの確認作業についてです。デザイナにはある程度できあがらないとテストや確認出来ない状態でしたし、
毎回自分のPCでビルドして渡すのはかなり面倒でした。（のでこの作業はほとんどやってない・・・）なので自分が修正
したらすぐに自分の実機やシミュレータでがんがん確認出来るような状況を作ればなと思っていました。会社だとjenkins
でビルドしてそれをダウンロードできる基盤があるのでそれ参考に個人でも作成してみようと思う。</p>

<p>肝心のiOS7でのおばけが表示されないバグがありますが先日修正したものを申請しましたのでもう少しでiOS7にした人も
使えることでしょう！！</p>

<p>とりあえず、リリースできてよかったのです。</p>

<p>また、いろんなことに挑戦していきたい。</p>

<p>今後はもう一度の使い方なり、AVFoundationのTipsをちょこちょこ書いていこうと思います。</p>
]]></content>
  </entry>
  
</feed>
